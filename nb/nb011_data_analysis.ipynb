{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a17ca6",
   "metadata": {
    "id": "d8a17ca6"
   },
   "source": [
    "# Overview\n",
    "- *Name*を用いて同じ家族を同定し、生存率を計算した新たな列*Family_SurvRate*を作成する。\n",
    "- *Ticket*を用いて上6桁が同じチケット番号のグループ分けし、生存率を計算した新たな列*Ticket_SurvRate*を作成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1da982",
   "metadata": {
    "id": "6c1da982"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333b95b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "333b95b7",
    "outputId": "8f72d9a7-ecdd-4d82-c327-d18f61f3f98c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/train.csv')   # Google Colabの場合はこちら\n",
    "data_train = pd.read_csv('../data/train.csv')   # ローカルの場合はこちら\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410b0bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/test.csv')   # Google Colabの場合はこちら\n",
    "data_test = pd.read_csv('../data/test.csv')   # ローカルの場合はこちら\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94bb22",
   "metadata": {},
   "source": [
    "### データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "86a30c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 1 to 1309\n",
      "Data columns (total 43 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Survived            891 non-null    float64\n",
      " 1   Pclass              1309 non-null   int64  \n",
      " 2   Age                 1309 non-null   float64\n",
      " 3   SibSp               1309 non-null   int64  \n",
      " 4   Parch               1309 non-null   int64  \n",
      " 5   Fare                1309 non-null   float64\n",
      " 6   TrainFlag           1309 non-null   bool   \n",
      " 7   Ticket_length       1309 non-null   int64  \n",
      " 8   Family_size         1309 non-null   int64  \n",
      " 9   Family_SurvRate     1309 non-null   float64\n",
      " 10  Family_SurvRate_NA  1309 non-null   int64  \n",
      " 11  Ticket_SurvRate     1309 non-null   float64\n",
      " 12  Ticket_SurvRate_NA  1309 non-null   int64  \n",
      " 13  Deck_predict        1309 non-null   int64  \n",
      " 14  Sex_male            1309 non-null   uint8  \n",
      " 15  Embarked_Q          1309 non-null   uint8  \n",
      " 16  Embarked_S          1309 non-null   uint8  \n",
      " 17  new_Deck_B          1309 non-null   uint8  \n",
      " 18  new_Deck_C          1309 non-null   uint8  \n",
      " 19  new_Deck_D          1309 non-null   uint8  \n",
      " 20  new_Deck_E          1309 non-null   uint8  \n",
      " 21  new_Deck_F          1309 non-null   uint8  \n",
      " 22  new_Deck_G          1309 non-null   uint8  \n",
      " 23  new_Deck_T          1309 non-null   uint8  \n",
      " 24  Title_Miss          1309 non-null   uint8  \n",
      " 25  Title_Mr            1309 non-null   uint8  \n",
      " 26  Title_Mrs           1309 non-null   uint8  \n",
      " 27  Title_Others        1309 non-null   uint8  \n",
      " 28  Ticket_first_2      1309 non-null   uint8  \n",
      " 29  Ticket_first_3      1309 non-null   uint8  \n",
      " 30  Ticket_first_4      1309 non-null   uint8  \n",
      " 31  Ticket_first_5      1309 non-null   uint8  \n",
      " 32  Ticket_first_6      1309 non-null   uint8  \n",
      " 33  Ticket_first_7      1309 non-null   uint8  \n",
      " 34  Ticket_first_8      1309 non-null   uint8  \n",
      " 35  Ticket_first_9      1309 non-null   uint8  \n",
      " 36  Ticket_first_A      1309 non-null   uint8  \n",
      " 37  Ticket_first_C      1309 non-null   uint8  \n",
      " 38  Ticket_first_F      1309 non-null   uint8  \n",
      " 39  Ticket_first_L      1309 non-null   uint8  \n",
      " 40  Ticket_first_P      1309 non-null   uint8  \n",
      " 41  Ticket_first_S      1309 non-null   uint8  \n",
      " 42  Ticket_first_W      1309 non-null   uint8  \n",
      "dtypes: bool(1), float64(5), int64(8), uint8(29)\n",
      "memory usage: 181.5 KB\n",
      "\n",
      "X_train: (891, 41)\n",
      "y_train: (891,)\n",
      "X_test: (418, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# 'TrainFlag'列追加\n",
    "data_train['TrainFlag'] = True\n",
    "data_test['TrainFlag'] = False\n",
    "\n",
    "# 訓練用とテスト用のデータ結合\n",
    "df = pd.concat([data_train, data_test])\n",
    "df.index = df['PassengerId']\n",
    "df = df.drop(\"PassengerId\", axis = 1)\n",
    "\n",
    "# =========\n",
    "# 欠損値処理\n",
    "# =========\n",
    "\n",
    "# 'Embarked'\n",
    "# -----------\n",
    "# 欠損値は2つだけなので、最頻値('S')で埋めることとする\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode().iloc[0])\n",
    "\n",
    "# 'Age'\n",
    "# -----\n",
    "# 'Age'は'Pclass'と相関が高いため、'Pclass'と'Sex'でグループ分けし、各グループの中央値で置き換える\n",
    "df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 'Cabin'\n",
    "# -------\n",
    "# 一文字目を取り出して新たな列'Deck'を作成、欠損値はZで置き換え\n",
    "df['Deck'] = df['Cabin'].apply(lambda d: d[0] if pd.notnull(d) else 'Z')\n",
    "\n",
    "# 'Fare'\n",
    "# ------\n",
    "# testデータに1つだけあるので、平均値で埋める\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "\n",
    "\n",
    "# =========\n",
    "# 特徴量生成\n",
    "# =========\n",
    "\n",
    "# 'Name'\n",
    "# ------\n",
    "# 'Mr'などのタイトルを抜き出して新たな列'Title'を作成\n",
    "df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# 'Master'、'Miss'、'Mr'、'Mrs'に統合もしくはその他('Others')とする\n",
    "df['Title'] = df['Title'].replace(['Mlle'], 'Miss')\n",
    "df['Title'] = df['Title'].replace(['Countess', 'Mme', 'Lady'], 'Mrs')\n",
    "df['Title'] = df['Title'].replace(['Capt', 'Col', 'Don', 'Dona', 'Dr', 'Jonkheer', 'Major', 'Ms', 'Rev', 'Sir'], 'Others')\n",
    "\n",
    "# 'Ticket'\n",
    "# --------\n",
    "# 'Ticket'の1文字目を抽出して新たな列'Ticket_first'作成\n",
    "df['Ticket_first'] = df['Ticket'].apply(lambda t: str(t)[0])\n",
    "\n",
    "# 'Ticket'の長さによる新たな列'Ticket_length'作成\n",
    "df['Ticket_length'] = df['Ticket'].apply(lambda t: len(str(t)))\n",
    "\n",
    "# 'Family_size'\n",
    "# -------------\n",
    "# 'SibSp'+'Parch'+1を新たな列'Family_size'に出力\n",
    "df['Family_size'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "\n",
    "# 'Family_SurvRate': 同じ姓(Surname)を持つ家族内の生存率\n",
    "# -------------------------------------------------------\n",
    "# Surnameを取り出す関数extract_surnameを定義\n",
    "def extract_surname(data):\n",
    "    families = []\n",
    "    \n",
    "    for i in range (len(data)):\n",
    "        name = data.iloc[i]\n",
    "        \n",
    "        # ()が付いている場合は、(の前までを取り出す\n",
    "        if '(' in name:\n",
    "            name_no_bracket = name.split('(')[0]\n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "        \n",
    "        # カンマ(,)の前までを姓として取り出す\n",
    "        surname = name_no_bracket.split(',')[0]\n",
    "        \n",
    "        # 句読点をスペースに置き換えてスペースを削除する\n",
    "        for p in string.punctuation:\n",
    "            surname.replace(p, ' ').strip()\n",
    "        \n",
    "        families.append(surname)\n",
    "    return families\n",
    "\n",
    "# 'Surname'列を追加\n",
    "df['Surname'] = extract_surname(df['Name'])\n",
    "\n",
    "# 一時的にtrainを分離\n",
    "df_temp_train = df[df['TrainFlag']==1]\n",
    "\n",
    "# Surnameでグループ分けしたDataFrameで'SurvivalRate'を計算\n",
    "df_temp_train_surname = pd.DataFrame(df_temp_train.groupby('Surname')['Survived'].sum())\n",
    "df_temp_train_surname['FamilySize'] = df_temp_train.groupby('Surname')['Surname'].count()\n",
    "df_temp_train_surname['SurvivalRate'] = df_temp_train_surname['Survived'] / df_temp_train_surname['FamilySize']\n",
    "\n",
    "# Surnameが1人の場合は生存率＝答えになってしまうので平均で埋める\n",
    "family_survrate_mean = np.mean(df_temp_train_surname['SurvivalRate'])\n",
    "df_temp_train_surname['SurvivalRate'].loc[df_temp_train_surname['FamilySize']==1] = family_survrate_mean\n",
    "\n",
    "# surname_dictに辞書形式で出力し、新たな列'Family_SurvRate'にmap関数で展開する\n",
    "surname_dict = df_temp_train_surname['SurvivalRate'].to_dict()\n",
    "df['Family_SurvRate'] = df['Surname']\n",
    "df['Family_SurvRate'] = df['Family_SurvRate'].map(surname_dict)\n",
    "\n",
    "# 'Family_SurvRate'がNaN（Testデータのみに固有のSurname）および1人しかいない'Surname'については\n",
    "# 平均で補完して'Family_SurvRate_NA'列に1を入れる\n",
    "df['Family_SurvRate'] = df['Family_SurvRate'].fillna(family_survrate_mean)\n",
    "df['Family_SurvRate_NA'] = 0\n",
    "df['Family_SurvRate_NA'].loc[df['Family_SurvRate']==family_survrate_mean] = 1   # 0:1 = 437:872\n",
    "\n",
    "\n",
    "# 'Ticket_SurvRate': チケット番号が似通っているグループ内の生存率\n",
    "# ----------------------------------------------------------------\n",
    "# Ticket_numを取り出す関数extract_ticketnumを定義\n",
    "def extract_ticketnum(data):\n",
    "    tickets = []\n",
    "    \n",
    "    for i in range (len(data)):\n",
    "        ticket = data.iloc[i]\n",
    "        \n",
    "        # スペースが入っている場合は、スペースの後ろをticket_numberとして取り出す\n",
    "        if ' ' in ticket:\n",
    "            ticket_number = ticket.split(' ')[1]\n",
    "        else:\n",
    "            ticket_number = ticket\n",
    "                \n",
    "        # ticket_numberの6桁目までを取り出す\n",
    "        ticket_ext = ticket_number[:6]\n",
    "        \n",
    "        tickets.append(ticket_ext)\n",
    "    return tickets\n",
    "\n",
    "# 'Ticlet_num'列を追加\n",
    "df['Ticket_num'] = extract_ticketnum(df['Ticket'])\n",
    "\n",
    "# 一時的にtrainを分離\n",
    "df_temp_train = df[df['TrainFlag']==1]\n",
    "\n",
    "# Ticket_numでグループ分けしたDataFrameで'SurvivalRate'を計算\n",
    "df_temp_train_ticketnum = pd.DataFrame(df_temp_train.groupby('Ticket_num')['Survived'].sum())\n",
    "df_temp_train_ticketnum['TicketSize'] = df_temp_train.groupby('Ticket_num')['Ticket_num'].count()\n",
    "df_temp_train_ticketnum['SurvivalRate'] = df_temp_train_ticketnum['Survived'] / df_temp_train_ticketnum['TicketSize']\n",
    "\n",
    "# Ticket_numが1人の場合は生存率＝答えになってしまうので平均で埋める\n",
    "ticketnum_survrate_mean = np.mean(df_temp_train_ticketnum['SurvivalRate'])\n",
    "df_temp_train_ticketnum['SurvivalRate'].loc[df_temp_train_ticketnum['TicketSize']==1] = ticketnum_survrate_mean\n",
    "\n",
    "# ticketnum_dictに辞書形式で出力し、新たな列'Ticket_SurvRate'にmap関数で展開する\n",
    "ticketnum_dict = df_temp_train_ticketnum['SurvivalRate'].to_dict()\n",
    "df['Ticket_SurvRate'] = df['Ticket_num']\n",
    "df['Ticket_SurvRate'] = df['Ticket_SurvRate'].map(ticketnum_dict)\n",
    "\n",
    "# 'Ticket_SurvRate'がNaN（Testデータのみに固有のTicket_num）および1人しかいない'Ticket_num'については\n",
    "# 平均で補完して'Ticket_SurvRate_NA'列に1を入れる\n",
    "df['Ticket_SurvRate'] = df['Ticket_SurvRate'].fillna(ticketnum_survrate_mean)\n",
    "df['Ticket_SurvRate_NA'] = 0\n",
    "df['Ticket_SurvRate_NA'].loc[df['Ticket_SurvRate']==ticketnum_survrate_mean] = 1   # 0:1 = 470:839\n",
    "\n",
    "\n",
    "# 'Deck': 'Cabin'欠損値（Z）を他の特徴量から予測する\n",
    "# ---------------------------------------------------\n",
    "# 'Deck'を予測するデータ（元々Zだったデータ）はわかるように'Deck_predict'列に1を入れる\n",
    "df['Deck_predict'] = 0\n",
    "df['Deck_predict'].loc[df['Deck']=='Z'] = 1   # 0:1 = 295:1014\n",
    "\n",
    "### 'Deck'予測用データ成形 ###\n",
    "df_Deck = df.drop(['Survived', 'TrainFlag'], axis=1)\n",
    "\n",
    "# 'Sex'、'Embarked'、'Title'、'Ticket_first'をone-hot-encodeする\n",
    "df_Deck_oh = pd.get_dummies(df_Deck[['Sex', 'Embarked', 'Title', 'Ticket_first']], drop_first=True)\n",
    "\n",
    "# one-hot-encodeデータを結合する\n",
    "df_Deck_added = pd.concat([df_Deck, df_Deck_oh], axis=1)\n",
    "\n",
    "# 'Name'、'Sex'、'Ticket'、'Cabin'、'Embarked'、'Title'、'Ticket_first'、'Surname'、'Ticket_num'を削除する\n",
    "df_Deck_deleted = df_Deck_added.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Title', 'Ticket_first',\n",
    "                                                      'Surname', 'Ticket_num'], axis=1)\n",
    "# 'Deck'予測用のtrainデータとtest（予測）データに分離\n",
    "df_Deck_X_train = df_Deck_deleted[df_Deck_deleted['Deck_predict']==0].drop(['Deck_predict', 'Deck'], axis=1)\n",
    "df_Deck_y_train = df_Deck_deleted[df_Deck_deleted['Deck_predict']==0]['Deck']\n",
    "df_Deck_X_test = df_Deck_deleted[df_Deck_deleted['Deck_predict']==1].drop(['Deck_predict', 'Deck'], axis=1)\n",
    "\n",
    "# Deck_X、Deck_yとしてNumpy配列にする\n",
    "Deck_X_train = df_Deck_X_train.values\n",
    "Deck_y_train = df_Deck_y_train.values\n",
    "Deck_X_test = df_Deck_X_test.values\n",
    "\n",
    "### 'Deck'予測モデル ###\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_deck = RandomForestClassifier(criterion='gini', n_estimators=100, random_state=21, n_jobs=-1)\n",
    "rf_deck.fit(Deck_X_train, Deck_y_train)\n",
    "new_Deck = rf_deck.predict(Deck_X_test)\n",
    "\n",
    "### 'Deck'予測データに置き換え ###\n",
    "df['new_Deck'] = df['Deck']\n",
    "df['new_Deck'].loc[df['Deck_predict']==1] = new_Deck\n",
    "\n",
    "\n",
    "# =========\n",
    "# 特徴量整理\n",
    "# =========\n",
    "\n",
    "# 'Sex'、'Embarked'、'new_Deck'、'Title'、'Ticket_first'をone-hot-encodeする\n",
    "df_oh = pd.get_dummies(df[['Sex', 'Embarked', 'new_Deck', 'Title', 'Ticket_first']], drop_first=True)\n",
    "\n",
    "# one-hot-encodeデータを結合する\n",
    "df_added = pd.concat([df, df_oh], axis=1)\n",
    "\n",
    "# 'Name'、'Sex'、'Ticket'、'Cabin'、'Embarked'、'Deck'、'Title'、'Ticket_first'、'Surname'、'Ticket_num', 'new_Deck'を削除する\n",
    "df_deleted = df_added.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Deck', 'Title', 'Ticket_first',\n",
    "                            'Surname', 'Ticket_num', 'new_Deck'], axis=1)\n",
    "df_deleted.info()\n",
    "\n",
    "# 訓練用とテスト用に再び分割\n",
    "df_train = df_deleted[df_deleted['TrainFlag']==True].drop(['TrainFlag'], axis=1)\n",
    "df_test = df_deleted[df_deleted['TrainFlag']==False].drop(['TrainFlag'], axis=1)\n",
    "\n",
    "# X、yとしてNumpy配列にする\n",
    "X_train = df_train.drop(['Survived'], axis=1).values\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = df_test.drop(['Survived'], axis=1).values\n",
    "\n",
    "print('\\nX_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc9f0b",
   "metadata": {},
   "source": [
    "### データ解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c2f8340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in y_train: [0 1] = [439 273]\n",
      "Label counts in y_train_test: [0 1] = [110  69]\n"
     ]
    }
   ],
   "source": [
    "# 訓練用、テスト用にデータ分割する\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_train_test, y_train, y_train_test = train_test_split(X_train, y_train, test_size=0.2,\n",
    "                                                                            random_state=21, stratify=y_train)   # 訓練:テスト = 80:20\n",
    "\n",
    "print('Label counts in y_train: [0 1] =', np.bincount(y_train.astype(np.int64)))\n",
    "print('Label counts in y_train_test: [0 1] =', np.bincount(y_train_test.astype(np.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6da6a6ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6da6a6ea",
    "outputId": "d8b698ae-df2e-4fae-8cf9-b515e8057fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best accuracy: 0.8847613458528951\n",
      "Best parameters: {'svc__C': 100.0, 'svc__gamma': 0.001, 'svc__kernel': 'sigmoid'}\n",
      "Test accuracy: 0.871508\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# Pipeline: pl_scv\n",
    "# SVC / k分割交差検証 / グリッドサーチ\n",
    "# =================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pl_svc = make_pipeline(StandardScaler(), SVC(random_state=21, max_iter=10000))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "svc_param_grid = [{'svc__C': svc_param_range, 'svc__kernel': ['linear']},\n",
    "                  {'svc__C': svc_param_range, 'svc__kernel': ['poly', 'rbf', 'sigmoid'], 'svc__gamma': svc_param_range}]\n",
    "svc_gs = GridSearchCV(estimator=pl_svc, param_grid=svc_param_grid, scoring='accuracy', cv=10, refit=True, n_jobs=-1)\n",
    "svc_gs.fit(X_train, y_train)\n",
    "\n",
    "print('CV best accuracy:', svc_gs.best_score_)\n",
    "print('Best parameters:', svc_gs.best_params_)\n",
    "svc_bestclf = svc_gs.best_estimator_\n",
    "print('Test accuracy: %f' % svc_bestclf.score(X_train_test, y_train_test))\n",
    "\n",
    "svc_pred = svc_bestclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "32f2e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best accuracy: 0.8875782472613458\n",
      "{'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': 20, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__n_estimators': 100}\n",
      "Test accuracy: 0.893855\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Pipeline: pl_randf\n",
    "# ランダムフォレスト / k分割交差検証 / グリッドサーチ\n",
    "# =============================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pl_randf = make_pipeline(RandomForestClassifier(random_state=21, n_jobs=-1))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_param_estimators_range = [100, 200, 300, 400, 500]\n",
    "rf_param_depth_range = [5, 10, 15, 20, 25, 30]\n",
    "rf_param_split_range = [5, 10, 15, 20, 25, 30]\n",
    "rf_param_grid = [{'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "                  'randomforestclassifier__n_estimators': rf_param_estimators_range,\n",
    "                  'randomforestclassifier__max_depth': rf_param_depth_range,\n",
    "                  'randomforestclassifier__min_samples_split': rf_param_split_range}]\n",
    "rf_gs = GridSearchCV(estimator=pl_randf, param_grid=rf_param_grid, scoring='accuracy', cv=10, refit=True, n_jobs=-1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "print('CV best accuracy:', rf_gs.best_score_)\n",
    "print(rf_gs.best_params_)\n",
    "rf_bestclf = rf_gs.best_estimator_\n",
    "print('Test accuracy: %f' % rf_bestclf.score(X_train_test, y_train_test))\n",
    "\n",
    "rf_pred = rf_bestclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6fb54671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best accuracy: 0.8862089201877934\n",
      "{'adaboostclassifier__algorithm': 'SAMME.R', 'adaboostclassifier__base_estimator__criterion': 'entropy', 'adaboostclassifier__base_estimator__max_depth': 1, 'adaboostclassifier__base_estimator__min_samples_split': 5, 'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 20}\n",
      "Test accuracy: 0.871508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Pipeline: pl_ada\n",
    "# ADA Boost / k分割交差検証 / グリッドサーチ\n",
    "# =============================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pl_ada = make_pipeline(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=21), random_state=21))\n",
    "ada_param_grid = [{'adaboostclassifier__base_estimator__criterion': ['gini', 'entropy'],\n",
    "                   'adaboostclassifier__base_estimator__max_depth': [1, 5, 10, 15, 20],\n",
    "                   'adaboostclassifier__base_estimator__min_samples_split': [1, 5, 10, 15, 20],\n",
    "                   'adaboostclassifier__algorithm': ['SAMME', 'SAMME.R'],\n",
    "                   'adaboostclassifier__n_estimators': [1, 5, 10, 15, 20, 25, 30],\n",
    "                   'adaboostclassifier__learning_rate': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "ada_gs = GridSearchCV(estimator=pl_ada, param_grid=ada_param_grid, scoring='accuracy', cv=10, refit=True, n_jobs=-1)\n",
    "ada_gs.fit(X_train, y_train)\n",
    "\n",
    "print('CV best accuracy:', ada_gs.best_score_)\n",
    "print(ada_gs.best_params_)\n",
    "ada_bestclf = ada_gs.best_estimator_\n",
    "print('Test accuracy: %f' % ada_bestclf.score(X_train_test, y_train_test))\n",
    "\n",
    "ada_pred = ada_bestclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e39dad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.888268\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 多数決アンサンブルモデル\n",
    "# ========================\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators=[('svc', svc_bestclf), ('rf', rf_bestclf), ('ada', ada_bestclf)])\n",
    "vote_clf.fit(X_train, y_train)\n",
    "\n",
    "print('Test accuracy: %f' % vote_clf.score(X_train_test, y_train_test))\n",
    "\n",
    "vote_pred = vote_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0ec57176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT8klEQVR4nO3df5DV9X3v8ec7CwYUjWRBa8EInRpNghTpkmAwNtGOSq4jONoMTQe4CXfID5PbJpmIdu5cNO1MkzFTG2Ojw4i9a2NXM9oR505GiSLxkqumi6UawF4IWWUZDCsYkSaMgu/7x36hywaQ3bOcc5bP8zGzs9/v5/vrfc7uvvZ7Pudzvt/ITCRJZXhXowuQJNWPoS9JBTH0Jakghr4kFcTQl6SCjGh0AUczbty4nDRpUqPLkKRhZe3ata9m5vjDLWvq0J80aRKdnZ2NLkOShpWIeOlIy+zekaSCGPqSVBBDX5IK0tR9+ofz1ltv0d3dzd69extdSlMYNWoUEydOZOTIkY0uRdIwMOxCv7u7m1NPPZVJkyYREY0up6Eyk507d9Ld3c3kyZMbXY6kYWDYde/s3buX1tbW4gMfICJobW31VY+kYzbsQh8w8PvwuZA0EMMy9CVJg/OOffoRcQ9wFbAjM6dUbe8FHgAmAV3ApzLzteg97fwO8Eng18B/zcznqm0WAv+j2u1fZ2b7UDyAuGVoz3Rz6bHdX+Dhhx/mmmuuYePGjZx//vn09PRw1VVX8eabb3L77bfzwgsv8MUvfnFIa5OkWh3LG7n/C7gDuLdP243AE5n5zYi4sZpfAswGzq2+PgLcCXyk+iexFGgDElgbEY9k5mtD9UDqraOjg4svvpiOjg5uueUWnnjiCS644ALuvvtuurq6+MIXvjCg0M9MMpN3vcsXX9JwFqtXD8l+8uMfH5L99PeOCZOZTwG7+jXPAQ6cqbcDc/u035u9ngFOj4izgCuAH2XmrirofwRcOQT1N8SePXtYs2YNy5cv5/7772fdunXccMMNrFixgmnTprFkyRJ+/vOfM23aNL7+9a8DcOuttzJjxgymTp3K0qVLAejq6uK8885jwYIFTJkyha1btzbyYUkqwGCHbJ6Zmdur6VeAM6vpCUDf5Oqu2o7UPiytWLGCK6+8kve///20trayf/9+vvGNb9DZ2ckdd9xBV1cX69evZ926dQCsXLmSTZs28dOf/pTM5Oqrr+app57ife97H5s2baK9vZ2ZM2c29kFJKkLNfQnZe5PdIbvRbkQsjojOiOjs6ekZqt0OqY6ODubNmwfAvHnz6OjoOOr6K1euZOXKlVx44YVMnz6dF198kU2bNgFwzjnnGPiS6mawZ/q/jIizMnN71X2zo2rfBpzdZ72JVds24OP92lcfbseZuQxYBtDW1tZ0d23ftWsXq1at4oUXXiAi2L9/PxHBhz70oSNuk5ncdNNNfO5znzukvauri1NOOeV4lyxJBw32TP8RYGE1vRBY0ad9QfSaCbxedQM9BlweEWMjYixwedU27Dz44IPMnz+fl156ia6uLrZu3crkyZMP6Y8/9dRTeeONNw7OX3HFFdxzzz3s2bMHgG3btrFjx47f2rckHW/HMmSzg96z9HER0U3vKJxvAj+IiEXAS8CnqtV/SO9wzc30Dtn8DEBm7oqIvwL+pVrvG5nZ/83hQTnWIZZDpaOjgyVLlhzSdu2117JkyRIWLVoEQGtrK7NmzWLKlCnMnj2bW2+9lY0bN3LRRRcBMGbMGL7//e/T0tJS19olKXq75JtTW1tb9r+JysaNG/nABz7QoIqak8+J1DyaYchmRKzNzLbDLXNQuCQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSrIsLtdYn9DNTzqgGMZJtXS0sIFF1xAZtLS0sIdd9zBRz/60aNuc/vtt3PnnXcyffp07rvvviGqVpIGZtiHfiOMHj364MXUHnvsMW666SZ+/OMfH3Wb733vezz++ONMnDjxmI6xb98+RozwxyNpaNm9U6Pdu3czduzYg/OHu4Ty5z//ebZs2cLs2bO57bbb2LVrF3PnzmXq1KnMnDmT559/HoCbb76Z+fPnM2vWLObPn09PTw/XXnstM2bMYMaMGfzkJz9pyGOUdOLwVHIQfvOb3zBt2jT27t3L9u3bWbVqFXDkSyjfddddPProozz55JOMGzeOL3/5y1x44YU8/PDDrFq1igULFhx85bBhwwbWrFnD6NGj+fSnP81XvvIVLr74Yl5++WWuuOIKNm7c2MBHLmm4M/QHoW/3ztNPP82CBQv42c9+dsgllKH3ZiubNm3ikksuOWT7NWvW8NBDDwFw6aWXsnPnTnbv3g3A1VdfzejRowF4/PHH2bBhw8Htdu/ezZ49exgzZszxfoiSTlCGfo0uuugiXn31VXp6eo54CeWB6Hup5bfffptnnnmGUaNGDUWpkmSffq1efPFF9u/fT2tr6zFfQvljH/vYwRE8q1evZty4cZx22mm/td7ll1/Od7/73YPzB15dSNJgDfsz/eN18+CjOdCnD703SGlvb6elpYXLL7/8sJdQPuOMMw7Z/uabb+azn/0sU6dO5eSTT6a9vb3/IYDeYZ7XX389U6dOZd++fVxyySXcddddx/WxSTqxeWnlE4DPidQ8vLSyJKlpGPqSVJBhGfrN3CVVbz4XkgZi2IX+qFGj2Llzp2FHb+Dv3LnTIZ2SjtmwG70zceJEuru76enpaXQpTWHUqFHHfD0fSRp2oT9y5EgmT57c6DIkaVgadt07kqTBM/QlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFaSm0I+Ir0TE+oj4WUR0RMSoiJgcEc9GxOaIeCAiTqrWfXc1v7laPmlIHoEk6ZgNOvQjYgLw34G2zJwCtADzgG8Bt2Xm7wOvAYuqTRYBr1Xtt1XrSZLqqNbunRHA6IgYAZwMbAcuBR6slrcDc6vpOdU81fLLIiJqPL4kaQAGHfqZuQ34NvAyvWH/OrAW+FVm7qtW6wYmVNMTgK3Vtvuq9Vv77zciFkdEZ0R0es18SRpatXTvjKX37H0y8LvAKcCVtRaUmcsysy0z28aPH1/r7iRJfdTSvfPHwC8ysycz3wL+GZgFnF519wBMBLZV09uAswGq5e8BdtZwfEnSANUS+i8DMyPi5Kpv/jJgA/AkcF21zkJgRTX9SDVPtXxVeqNbSaqrWvr0n6X3DdnngBeqfS0DlgBfjYjN9PbZL682WQ60Vu1fBW6soW5J0iDUdI/czFwKLO3XvAX48GHW3Qv8SS3HkyTVxk/kSlJBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKUtNNVCQ1j7glat5HLvUOpic6z/QlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqSE2hHxGnR8SDEfFiRGyMiIsi4r0R8aOI2FR9H1utGxFxe0RsjojnI2L60DwESdKxqvVM/zvAo5l5PvAHwEbgRuCJzDwXeKKaB5gNnFt9LQburPHYkqQBGnToR8R7gEuA5QCZ+WZm/gqYA7RXq7UDc6vpOcC92esZ4PSIOGuwx5ckDVwtZ/qTgR7gHyLiXyPi7og4BTgzM7dX67wCnFlNTwC29tm+u2o7REQsjojOiOjs6empoTxJUn+1hP4IYDpwZ2ZeCPwH/9mVA0BmJjCgm25m5rLMbMvMtvHjx9dQniSpv1pCvxvozsxnq/kH6f0n8MsD3TbV9x3V8m3A2X22n1i1SZLqZNChn5mvAFsj4ryq6TJgA/AIsLBqWwisqKYfARZUo3hmAq/36QaSJNXBiBq3/zJwX0ScBGwBPkPvP5IfRMQi4CXgU9W6PwQ+CWwGfl2tK0mqo5pCPzPXAW2HWXTZYdZN4PpajidJqo2fyJWkghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBXE0Jekghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVpObQj4iWiPjXiPjf1fzkiHg2IjZHxAMRcVLV/u5qfnO1fFKtx5YkDcxQnOn/ObCxz/y3gNsy8/eB14BFVfsi4LWq/bZqPUlSHdUU+hExEfgvwN3VfACXAg9Wq7QDc6vpOdU81fLLqvUlSXVS65n+3wE3AG9X863ArzJzXzXfDUyopicAWwGq5a9X6x8iIhZHRGdEdPb09NRYniSpr0GHfkRcBezIzLVDWA+ZuSwz2zKzbfz48UO5a0kq3ogatp0FXB0RnwRGAacB3wFOj4gR1dn8RGBbtf424GygOyJGAO8BdtZwfEnSAA36TD8zb8rMiZk5CZgHrMrMPwOeBK6rVlsIrKimH6nmqZavyswc7PElSQN3PMbpLwG+GhGb6e2zX161Lwdaq/avAjceh2NLko6ilu6dgzJzNbC6mt4CfPgw6+wF/mQojidJGhw/kStJBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiKEvSQUx9CWpIIa+JBXE0Jekghj6klQQQ1+SCmLoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIIY+pJUEENfkgpi6EtSQQx9SSqIoS9JBTH0Jakghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqyKBDPyLOjognI2JDRKyPiD+v2t8bET+KiE3V97FVe0TE7RGxOSKej4jpQ/UgJEnHppYz/X3A1zLzg8BM4PqI+CBwI/BEZp4LPFHNA8wGzq2+FgN31nBsSdIgDDr0M3N7Zj5XTb8BbAQmAHOA9mq1dmBuNT0HuDd7PQOcHhFnDfb4kqSBG5I+/YiYBFwIPAucmZnbq0WvAGdW0xOArX02667a+u9rcUR0RkRnT0/PUJQnSarUHPoRMQZ4CPiLzNzdd1lmJpAD2V9mLsvMtsxsGz9+fK3lSZL6qCn0I2IkvYF/X2b+c9X8ywPdNtX3HVX7NuDsPptPrNokSXVSy+idAJYDGzPzb/ssegRYWE0vBFb0aV9QjeKZCbzepxtIklQHI2rYdhYwH3ghItZVbX8JfBP4QUQsAl4CPlUt+yHwSWAz8GvgMzUcW5I0CIMO/cxcA8QRFl92mPUTuH6wx5Mk1a6WM32pruKWI51jDEwuHdDYAumE4mUYJKkghr4kFcTQl6SCGPqSVBBDX5IKYuhLUkEMfUkqiOP0dUSOi5dOPJ7pS1JBPNOXBslXQhqOPNOXpIIY+pJUEENfkgpi6EtSQQx9SSqIo3cKFatXv/NKf/TkO6/z40/UXIuk+jH0JQ05h7M2L0O/ifiHIul4s09fkgpi6EtSQQx9SSqIffp14mgZSc3AM31JKoihL0kFsXtHTcHuL6k+DH3pMPwnpBOV3TuSVBBDX5IKUnT3jpc9kFSaEzr037Ff1j5ZSYU5oUNfOlEMyRvLnsCIBvTpR8SVEfHvEbE5Im6s9/ElqWR1Df2IaAH+HpgNfBD404j4YD1rkKSS1bt758PA5szcAhAR9wNzgA11rkPSIPkZhuEtMus38iQirgOuzMz/Vs3PBz6SmV/qs85iYHE1ex7w78expHHAq8dx/wNlPUdnPUfXTPU0Uy1QXj3nZOb4wy1oujdyM3MZsKwex4qIzsxsq8exjoX1HJ31HF0z1dNMtYD19FXvN3K3AWf3mZ9YtUmS6qDeof8vwLkRMTkiTgLmAY/UuQZJKlZdu3cyc19EfAl4DGgB7snM9fWsoZ+6dCMNgPUcnfUcXTPV00y1gPUcVNc3ciVJjeUF1ySpIIa+JBWk2NCPiLkRkRFxfhPUsj8i1kXEv0XEcxHx0QbX8zsRcX9E/Dwi1kbEDyPi/Q2q5cBzs756fr4WEQ39ve1T04Gvhl5O5DD1TGpgLWdGxD9FxJbqd+fpiLimQbW09nlOXomIbX3mT2pAPdf0+zmti4i3I2J2XesotU8/Ih4AfhdYlZlLG1zLnswcU01fAfxlZv5Rg2oJ4P8C7Zl5V9X2B8Bpmfl/GlBP3+fmDOCfgJ808mfWt6Zm0Cz1HOF35xzg6sz8boNruxnYk5nfbmQdfVUfRP0z4BOZ+Xa9jlvkmX5EjAEuBhbRO2y0mZwGvNbA438CeOvAHy1AZv5bIwK/v8zcQe+ntb9UBYyay6XAm/1+d15qdOA3o+qV8/8E5tcz8KEJP5FbJ3OARzPz/0XEzoj4w8xc28B6RkfEOmAUcBa9fzyNMgVo5HNxVJm5pbpw3xnALxtUxoGf1wF/k5kPNKgWOLSeX2RmQ7pTgA8BzzXo2MNGRIyk9xXr1zLz5Xofv9TQ/1PgO9X0/dV8I4PuN5k5DSAiLgLujYgpWWrfW/M7+PNqEs1WDwAR8ff0vqJ+MzNnNLqeJvJXwPpGnSgUF/oR8V56z6QviIik90NiGRFfb4aQzcynI2IcMB7Y0YAS1gPXNeC4xyQifg/YT2OeGx3deuDaAzOZeX31u9zZuJKaS0R8nN7naHqjaiixT/864B8z85zMnJSZZwO/AD7W4LoAqEYTtQA7G1TCKuDd1ZtMB2qaGhENf34iYjxwF3BHM/yD1m9ZBYyKiC/0aTu5UcU0m4gYC/wDsCAz32hUHcWd6dPblfOtfm0PVe1P1b8c4NA+2QAWZub+RhSSmVkNsfu7iFgC7AW6gL9oRD3853MzEtgH/CPwtw2q5YD+ffqPZmbxd4GrfnfmArdFxA1AD/AfwJKGFtY8Pk/ve1F39huHUNf3hIodsilJJSqxe0eSimXoS1JBDH1JKoihL0kFMfQlqSCGviQVxNCXpIL8fx5UCHxc201fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cabin_plot_before = df.groupby(df['Deck'])['Deck'].count()\n",
    "cabin_plot_after = df.groupby(df['new_Deck'])['new_Deck'].count()\n",
    "\n",
    "cabin_plot = pd.concat([cabin_plot_before, cabin_plot_after], axis=1, join='outer')\n",
    "cabin_plot\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(cabin_plot.index, cabin_plot.iloc[:, 1], width=0.5, color='g', label='After', align='edge')\n",
    "plt.bar(cabin_plot.index, cabin_plot.iloc[:, 0], width=0.5, color='c', label='Before')\n",
    "plt.legend()\n",
    "\n",
    "# プロット画像保存\n",
    "plt.savefig('../image/nb011_Deck.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nb007_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
