{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a17ca6",
   "metadata": {
    "id": "d8a17ca6"
   },
   "source": [
    "# Overview\n",
    "- nb007までは取り除いていた*Name*、*Ticket*、*Cabin*を特徴量として取り扱えるよう、データ処理を行う。\n",
    "- *Age*は*Sex*と*Pclass*のグループごとに中央値で補完。*Embarked*は最頻値で補完。*Cabin*は先頭のアルファベットを抽出し、欠損値はZで補完。\n",
    "- *Name*からTitleを取り出し、Master、Miss、Mr、Mrs、Othersに分類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1da982",
   "metadata": {
    "id": "6c1da982"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333b95b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "333b95b7",
    "outputId": "8f72d9a7-ecdd-4d82-c327-d18f61f3f98c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/train.csv')   # Google Colabの場合はこちら\n",
    "df_train = pd.read_csv('../data/train.csv')   # ローカルの場合はこちら\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d16fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64 \n",
      "\n",
      "Nan in y: 0\n"
     ]
    }
   ],
   "source": [
    "# 特徴量をX,ラベルをyとして分離する\n",
    "df_train_X = df_train.drop(['Survived'], axis=1)\n",
    "df_train_y = df_train['Survived']\n",
    "print(df_train_X.isnull().sum(), '\\n')\n",
    "print('Nan in y: %d' % df_train_y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91cca7",
   "metadata": {},
   "source": [
    "### 欠損値処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7a8c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "\n",
      "After: \n",
      "S    646\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'Embarked'の欠損値処理\n",
    "# =======================\n",
    "\n",
    "print('Before: \\n%s\\n' % df_train_X['Embarked'].value_counts())\n",
    "\n",
    "# 欠損値は2つだけなので、最頻値('S')で埋めることとする\n",
    "df_train_X['Embarked'] = df_train_X['Embarked'].fillna(df_train_X['Embarked'].mode().iloc[0])\n",
    "\n",
    "print('After: \\n%s\\n' % df_train_X['Embarked'].value_counts())\n",
    "print(df_train_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c26b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0.036847\n",
      "Survived      -0.077221\n",
      "Pclass        -0.369226\n",
      "Age            1.000000\n",
      "SibSp         -0.308247\n",
      "Parch         -0.189119\n",
      "Fare           0.096067\n",
      "dtype: float64 \n",
      "\n",
      "Pclass  Sex   \n",
      "1       female    35.0\n",
      "        male      40.0\n",
      "2       female    28.0\n",
      "        male      30.0\n",
      "3       female    21.5\n",
      "        male      25.0\n",
      "Name: Age, dtype: float64 \n",
      "\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'Age'の欠損値処理\n",
    "# ==================\n",
    "\n",
    "print(df_train.corrwith(df_train['Age']), '\\n')\n",
    "\n",
    "# 'Age'は'Pclass'と相関が高いため、'Pclass'と'Sex'でグループ分けし、各グループの中央値で置き換える\n",
    "print(df_train_X.groupby(['Pclass', 'Sex'])['Age'].median(), '\\n')\n",
    "df_train_X['Age'] = df_train_X.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "print(df_train_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205ed5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "Deck             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 'Cabin'の欠損値処理\n",
    "# ====================\n",
    "\n",
    "df_train_X['Cabin'].unique()\n",
    "\n",
    "# 一文字目を取り出して新たな列'Deck'を作成、欠損値はZで置き換え\n",
    "df_train_X['Deck'] = df_train_X['Cabin'].apply(lambda d: d[0] if pd.notnull(d) else 'Z')\n",
    "df_train_X['Deck'].unique()\n",
    "print(df_train_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0bdf0",
   "metadata": {},
   "source": [
    "### 特徴量生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd25e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Capt          1\n",
      "Col           2\n",
      "Countess      1\n",
      "Don           1\n",
      "Dr            7\n",
      "Jonkheer      1\n",
      "Lady          1\n",
      "Major         2\n",
      "Master       40\n",
      "Miss        182\n",
      "Mlle          2\n",
      "Mme           1\n",
      "Mr          517\n",
      "Mrs         125\n",
      "Ms            1\n",
      "Rev           6\n",
      "Sir           1\n",
      "Name: Name, dtype: int64 \n",
      "\n",
      "['Mr' 'Mrs' 'Miss' 'Master' 'Others']\n"
     ]
    }
   ],
   "source": [
    "# 'Name'の特徴量生成\n",
    "# ===================\n",
    "\n",
    "# 'Mr'などのタイトルを抜き出して新たな列'Title'を作成\n",
    "df_train_X['Title'] = df_train_X['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "print(df_train_X.groupby(['Title'])['Name'].count(), '\\n')\n",
    "\n",
    "# 'Master'、'Miss'、'Mr'、'Mrs'に統合もしくはその他('Others')とする\n",
    "df_train_X['Title'] = df_train_X['Title'].replace(['Mlle'], 'Miss')\n",
    "df_train_X['Title'] = df_train_X['Title'].replace(['Countess', 'Mme', 'Lady'], 'Mrs')\n",
    "df_train_X['Title'] = df_train_X['Title'].replace(['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Major', 'Ms', 'Rev', 'Sir'], 'Others')\n",
    "\n",
    "print(df_train_X['Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fac3f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "      <th>Ticket_first</th>\n",
       "      <th>Ticket_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Z</td>\n",
       "      <td>Mr</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>P</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Z</td>\n",
       "      <td>Miss</td>\n",
       "      <td>S</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Z</td>\n",
       "      <td>Mr</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked Deck  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S    Z   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C    C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S    Z   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S    C   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S    Z   \n",
       "\n",
       "  Title Ticket_first  Ticket_length  \n",
       "0    Mr            A              9  \n",
       "1   Mrs            P              8  \n",
       "2  Miss            S             16  \n",
       "3   Mrs            1              6  \n",
       "4    Mr            3              6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Ticket'の特徴量生成\n",
    "# =====================\n",
    "\n",
    "# 'Ticket'の1文字目を抽出して新たな列'Ticket_first'作成\n",
    "df_train_X['Ticket_first'] = df_train_X['Ticket'].apply(lambda t: str(t)[0])\n",
    "\n",
    "# 'Ticket'の長さによる新たな列'Ticket_length'作成\n",
    "df_train_X['Ticket_length'] = df_train_X['Ticket'].apply(lambda t: len(str(t)))\n",
    "\n",
    "df_train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe9b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family_size\n",
       "1     537\n",
       "2     161\n",
       "3     102\n",
       "4      29\n",
       "5      15\n",
       "6      22\n",
       "7      12\n",
       "8       6\n",
       "11      7\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Family_size'の作成\n",
    "# ====================\n",
    "\n",
    "# 'SibSp'+'Parch'+1を新たな列'Family_size'に出力\n",
    "df_train_X['Family_size'] = df_train_X['SibSp'] + df_train['Parch'] + 1\n",
    "\n",
    "df_train_X.groupby(['Family_size'])['PassengerId'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040df09",
   "metadata": {},
   "source": [
    "### 特徴量整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44420dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 46)\n",
      "(891, 38) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 38 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   PassengerId     891 non-null    int64  \n",
      " 1   Pclass          891 non-null    int64  \n",
      " 2   Age             891 non-null    float64\n",
      " 3   SibSp           891 non-null    int64  \n",
      " 4   Parch           891 non-null    int64  \n",
      " 5   Fare            891 non-null    float64\n",
      " 6   Ticket_length   891 non-null    int64  \n",
      " 7   Family_size     891 non-null    int64  \n",
      " 8   Sex_male        891 non-null    uint8  \n",
      " 9   Embarked_Q      891 non-null    uint8  \n",
      " 10  Embarked_S      891 non-null    uint8  \n",
      " 11  Deck_B          891 non-null    uint8  \n",
      " 12  Deck_C          891 non-null    uint8  \n",
      " 13  Deck_D          891 non-null    uint8  \n",
      " 14  Deck_E          891 non-null    uint8  \n",
      " 15  Deck_F          891 non-null    uint8  \n",
      " 16  Deck_G          891 non-null    uint8  \n",
      " 17  Deck_T          891 non-null    uint8  \n",
      " 18  Deck_Z          891 non-null    uint8  \n",
      " 19  Title_Miss      891 non-null    uint8  \n",
      " 20  Title_Mr        891 non-null    uint8  \n",
      " 21  Title_Mrs       891 non-null    uint8  \n",
      " 22  Title_Others    891 non-null    uint8  \n",
      " 23  Ticket_first_2  891 non-null    uint8  \n",
      " 24  Ticket_first_3  891 non-null    uint8  \n",
      " 25  Ticket_first_4  891 non-null    uint8  \n",
      " 26  Ticket_first_5  891 non-null    uint8  \n",
      " 27  Ticket_first_6  891 non-null    uint8  \n",
      " 28  Ticket_first_7  891 non-null    uint8  \n",
      " 29  Ticket_first_8  891 non-null    uint8  \n",
      " 30  Ticket_first_9  891 non-null    uint8  \n",
      " 31  Ticket_first_A  891 non-null    uint8  \n",
      " 32  Ticket_first_C  891 non-null    uint8  \n",
      " 33  Ticket_first_F  891 non-null    uint8  \n",
      " 34  Ticket_first_L  891 non-null    uint8  \n",
      " 35  Ticket_first_P  891 non-null    uint8  \n",
      " 36  Ticket_first_S  891 non-null    uint8  \n",
      " 37  Ticket_first_W  891 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(30)\n",
      "memory usage: 81.9 KB\n"
     ]
    }
   ],
   "source": [
    "# 'Sex'、'Embarked'、'Deck'、'Title'、'Ticket_first'をone-hot-encodeする\n",
    "df_train_X_oh = pd.get_dummies(df_train_X[['Sex', 'Embarked', 'Deck', 'Title', 'Ticket_first']], drop_first=True)\n",
    "\n",
    "# one-hot-encodeデータを結合する\n",
    "df_train_X_added = pd.concat([df_train_X, df_train_X_oh], axis=1)\n",
    "print(df_train_X_added.shape)\n",
    "\n",
    "# 'Name'、'Sex'、'Ticket'、'Cabin'、'Embarked'、'Deck'、'Title'、'Ticket_first'を削除する\n",
    "df_train_X_deleted = df_train_X_added.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Deck', 'Title', 'Ticket_first'], axis=1)\n",
    "print(df_train_X_deleted.shape, '\\n')\n",
    "df_train_X_deleted.info()\n",
    "\n",
    "# X、yとしてNumpy配列にする\n",
    "X = df_train_X_deleted.values\n",
    "y = df_train_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc9f0b",
   "metadata": {},
   "source": [
    "### データ解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f8340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts in y: [0 1] = [549 342]\n",
      "Label counts in y_train: [0 1] = [439 273]\n",
      "Label counts in y_test: [0 1] = [110  69]\n"
     ]
    }
   ],
   "source": [
    "# 訓練用、テスト用にデータ分割する   # 本当は最初にしたほうがいい\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)   # 訓練:テスト = 80:20\n",
    "\n",
    "print('Label counts in y: [0 1] =', np.bincount(y))\n",
    "print('Label counts in y_train: [0 1] =', np.bincount(y_train))\n",
    "print('Label counts in y_test: [0 1] =', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da6a6ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6da6a6ea",
    "outputId": "d8b698ae-df2e-4fae-8cf9-b515e8057fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best accuracy: 0.8482394366197182\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Test accuracy: 0.832402\n"
     ]
    }
   ],
   "source": [
    "# Pipeline: pl_scv\n",
    "# SVC / k分割交差検証 / グリッドサーチ\n",
    "# =====================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pl_svc = make_pipeline(StandardScaler(), SVC(C=10.0, kernel='rbf', gamma=0.01, random_state=21, max_iter=5000))   # CVの最適値入力済\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, 'svc__kernel': ['poly', 'rbf', 'sigmoid'], 'svc__gamma': param_range}]\n",
    "gs = GridSearchCV(estimator=pl_svc, param_grid=param_grid, scoring='accuracy', cv=10, refit=True, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "print('CV best accuracy:', gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "bestclf = gs.best_estimator_\n",
    "print('Test accuracy: %f' % bestclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f2e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV best accuracy: 0.8413145539906102\n",
      "{'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 8, 'randomforestclassifier__n_estimators': 400}\n",
      "Test accuracy: 0.810056\n"
     ]
    }
   ],
   "source": [
    "# Pipeline: pl_randf\n",
    "# ランダムフォレスト / k分割交差検証 / グリッドサーチ\n",
    "# ====================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pl_randf = make_pipeline(RandomForestClassifier(criterion='entropy', n_estimators=400, \n",
    "                                                max_depth=8, random_state=21, n_jobs=2))   # CVの最適値入力済\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_estimators_range = [100, 200, 300, 400, 500]\n",
    "param_depth_range = [4, 6, 8, 10]\n",
    "param_grid = [{'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "               'randomforestclassifier__n_estimators': param_estimators_range,\n",
    "               'randomforestclassifier__max_depth': param_depth_range}]\n",
    "gs = GridSearchCV(estimator=pl_randf, param_grid=param_grid, scoring='accuracy', cv=10, refit=True, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "print('CV best accuracy:', gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "bestclf = gs.best_estimator_\n",
    "print('Test accuracy: %f' % bestclf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "# ===============\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "fig = plt.figure(figsize=(9.6, 3.2), dpi=100)\n",
    "\n",
    "# SVCのプロット\n",
    "svc_train_sizes, svc_train_scores, svc_valid_scores = learning_curve(estimator=pl_svc, X=X_train, y=y_train,\n",
    "                                                       train_sizes=np.linspace(0.1, 1, 10), cv=10, n_jobs=-1)\n",
    "svc_train_mean = np.mean(svc_train_scores, axis=1)\n",
    "svc_train_std = np.std(svc_train_scores, axis=1)\n",
    "svc_valid_mean = np.mean(svc_valid_scores, axis=1)\n",
    "svc_valid_std = np.std(svc_valid_scores, axis=1)\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(svc_train_sizes, svc_train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')\n",
    "plt.fill_between(svc_train_sizes, svc_train_mean+svc_train_std, svc_train_mean-svc_train_std, color='blue', alpha=0.2)\n",
    "plt.plot(svc_train_sizes, svc_valid_mean, color='green', marker='s', markersize=5, linestyle='--', label='Validation accuracy')\n",
    "plt.fill_between(svc_train_sizes, svc_valid_mean+svc_valid_std, svc_valid_mean-svc_valid_std, color='green', alpha=0.2)\n",
    "plt.grid()\n",
    "plt.title('SVC')\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# ランダムフォレストのプロット\n",
    "randf_train_sizes, randf_train_scores, randf_valid_scores = learning_curve(estimator=pl_randf, X=X_train, y=y_train,\n",
    "                                                       train_sizes=np.linspace(0.1, 1, 10), cv=10, n_jobs=-1)\n",
    "randf_train_mean = np.mean(randf_train_scores, axis=1)\n",
    "randf_train_std = np.std(randf_train_scores, axis=1)\n",
    "randf_valid_mean = np.mean(randf_valid_scores, axis=1)\n",
    "randf_valid_std = np.std(randf_valid_scores, axis=1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(randf_train_sizes, randf_train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')\n",
    "plt.fill_between(randf_train_sizes, randf_train_mean+randf_train_std, randf_train_mean-randf_train_std, color='blue', alpha=0.2)\n",
    "plt.plot(randf_train_sizes, randf_valid_mean, color='green', marker='s', markersize=5, linestyle='--', label='Validation accuracy')\n",
    "plt.fill_between(randf_train_sizes, randf_valid_mean+randf_valid_std, randf_valid_mean-randf_valid_std, color='green', alpha=0.2)\n",
    "plt.grid()\n",
    "plt.title('Random Forest Classifier')\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# プロット画像保存\n",
    "plt.savefig('../image/nb008_learningcurve.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nb007_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
